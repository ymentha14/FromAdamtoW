{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.debugger import set_trace\n",
    "from scipy.io import wavfile\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from speechpy.feature import mfcc\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful dics to convert labels from german to english\n",
    "DE2EN = {'W':'A', #Wut-Anger\n",
    "         'L':'B', #Langeweile-Bordom\n",
    "         'E':'D', #Ekel-Disgust\n",
    "         'A':'F', #Angst-Fear\n",
    "         'F':'H', #Freude-Happiness\n",
    "         'T':'S', #Traueer-Sadness\n",
    "         'N':'N'} #Neutral\n",
    "\n",
    "DE2NUM = {item[0]:num for item,num in zip(DE2EN.items(),range(len(DE2EN)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechModel(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN classifier: inspired from \"Emotion Recognition from Speech\" (Kannan Venkataramanan,Haresh Rengaraj Rajamohan,2019)\n",
    "    https://www.researchgate.net/publication/338138024_Emotion_Recognition_from_Speech\n",
    "\n",
    "    Attributes:\n",
    "        convblock[i] (nn.Sequential) : various convolutional blocks\n",
    "        linblock (nn.Sequential): output layer\n",
    "    Methods:\n",
    "        forward : regular forward overriding\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SpeechModel,self).__init__()\n",
    "        self.convblock1 = nn.Sequential(\n",
    "                                nn.Conv2d(1,8,kernel_size=13),\n",
    "                                nn.BatchNorm2d(8),\n",
    "                                nn.ReLU())\n",
    "        self.convblock2 = nn.Sequential(\n",
    "                                nn.Conv2d(8,8,kernel_size=13),\n",
    "                                nn.BatchNorm2d(8),\n",
    "                                nn.Dropout(0.33),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=(2,1)))\n",
    "        self.convblock3 = nn.Sequential(\n",
    "                                nn.Conv2d(8,8,kernel_size=13),\n",
    "                                nn.BatchNorm2d(8),\n",
    "                                nn.Dropout(0.33),\n",
    "                                nn.ReLU())\n",
    "\n",
    "        self.convblock4 = nn.Sequential(\n",
    "                                nn.Conv2d(8,8,kernel_size=2),\n",
    "                                nn.BatchNorm2d(8),\n",
    "                                nn.Dropout(0.33),\n",
    "                                nn.ReLU(),\n",
    "                                nn.MaxPool2d(kernel_size=(2,1)))\n",
    "        self.linblock = nn.Sequential(\n",
    "                                nn.Flatten(),\n",
    "                                nn.Linear(1456,64),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Dropout(0.2),\n",
    "                                nn.Linear(64,7))\n",
    "    def forward(self,x):\n",
    "        x = self.convblock1(x.float())\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = self.convblock4(x)\n",
    "        x = self.linblock(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropadd(data,mode='max'):\n",
    "    \"\"\"\n",
    "    zero padds the audio files\n",
    "    \n",
    "    Args:\n",
    "        mode(str):'max' or 'mean' if set to max, zero padds all the files to the max length of these files. Otherwise zero padds/cuts to the mean size.\n",
    "        data(np.array): audio data\n",
    "    Returns:\n",
    "        data_padded(int): same data as in the arg, but zeropadded\n",
    "    \"\"\"\n",
    "    if mode == 'max':\n",
    "        new_len = max([x.shape[0] for x in data])\n",
    "    else:\n",
    "        new_len = int(np.round(np.mean([x.shape[0] for x in data])*1.5))\n",
    "    def padd(x):\n",
    "        diff = abs(new_len - x.shape[0])\n",
    "        shift = diff %2\n",
    "        diff //=2\n",
    "        if x.shape[0] < new_len:\n",
    "            return np.pad(x,(diff,diff+shift),'constant')\n",
    "        else:\n",
    "            return x[diff:-(diff+shift)]\n",
    "    data_padded = np.zeros((len(data),new_len))\n",
    "    for i,x in enumerate(data):\n",
    "        data_padded[i] = padd(x)\n",
    "    return data_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc(data,sfs):\n",
    "    \"\"\"\n",
    "    load the wav data\n",
    "    Args:\n",
    "        data(np.array): audio files\n",
    "        sfs(np.array(int)): frequencies of the audio data\n",
    "    Returns:\n",
    "        (np.array): mel-frequency cepstrum of the audio data\n",
    "    \"\"\"\n",
    "    if isinstance(sfs,(int,np.int64)):\n",
    "        sfs = [sfs for i in range(len(data))]\n",
    "    ret = np.array([mfcc(x,sf,num_cepstral=39) for x,sf in zip(data,sfs)])\n",
    "    return np.expand_dims(ret,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset to load wav files from EmoDB \n",
    "    \"\"\"\n",
    "    def __init__(self, data_root):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_root: path to the wav files directory\n",
    "        \"\"\"\n",
    "        self.samples = []\n",
    "        data_root = Path(data_root)\n",
    "        \n",
    "        data,sfs,targets,file_names = [],[],[],[]\n",
    "        for file in data_root.iterdir():\n",
    "            \n",
    "            sf,audio_data = wavfile.read(file)\n",
    "            data.append(audio_data)\n",
    "            sfs.append(sf)\n",
    "            target = DE2NUM[file.name[5].capitalize()]\n",
    "            targets.append(target)\n",
    "            file_names.append(file.name)\n",
    "            \n",
    "        data = zeropadd(data,mode='mean')\n",
    "        file_names = np.array(file_names)\n",
    "        sfs = np.array(sfs)\n",
    "        targets = np.array(targets)\n",
    "        order = np.argsort(file_names)\n",
    "        data = data[order]\n",
    "        self.targets = targets[order]\n",
    "        self.filenames = file_names[order]\n",
    "        assert(all([i == sfs[0] for i in sfs]))\n",
    "        self.sfs = sfs[0]\n",
    "        self.data = get_mfcc(data,self.sfs)\n",
    "        assert(len(self.data) == len(self.filenames))\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx]\n",
    "        y = self.targets[idx]\n",
    "        name = self.filenames[idx]\n",
    "        return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"\n",
    "    return the pytorch model that performs decently on the EmoDB dataset\n",
    "    \"\"\"\n",
    "    # double necessary to work with the mfcc features\n",
    "    return SpeechModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    return the DataLoader necessary for EmoDB\n",
    "    \"\"\"\n",
    "    dataset = SpeechDataset(\"../data/wav/\")\n",
    "    dataloader = DataLoader(dataset, batch_size=20, shuffle=True, num_workers=1)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training Model\n",
      "Epoch:0/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ymentha/anaconda3/envs/ML/lib/python3.7/multiprocessing/queues.py\", line 242, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ymentha/anaconda3/envs/ML/lib/python3.7/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ymentha/anaconda3/envs/ML/lib/python3.7/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ymentha/anaconda3/envs/ML/lib/python3.7/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4e836f1751ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ML/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = load_model()\n",
    "dataloader = load_data()\n",
    "nb_epochs = 4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "print(\"Start training Model\")\n",
    "for e in range(nb_epochs):\n",
    "    print(\"Epoch:{}/{}\".format(e,nb_epochs))\n",
    "    for X_batch,y_batch in dataloader:\n",
    "        output_batch = model(X_batch)\n",
    "        loss = criterion(output_batch,y_batch)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if callback is not None:\n",
    "        callback(model,X_train,X_test,history,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
